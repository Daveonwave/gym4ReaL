{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 : Init RoboFeeder Env\n",
    "This cell sets up the environment for the RoboFeeder simulation by importing necessary modules and configuring the Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/edge/Desktop/gym4ReaL'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "dir = os.getcwd()\n",
    "if 'examples' in dir:\n",
    "    os.chdir(os.getcwd().split('examples')[0])\n",
    "else:\n",
    "    print(\"please set the working directory to the root of the gym4ReaL repository\")\n",
    "\n",
    "# check if the current working directory is the root of the gym4ReaL repository\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Import Required Modules\n",
    "This cell imports the necessary modules and updates the system path to include the gym4ReaL repository. It also imports the robot simulator and matplotlib for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.getcwd())  # <-- path to the *parent* of gym4real\n",
    "\n",
    "import torch as th\n",
    "from stable_baselines3 import PPO\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "import gymnasium as gym"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Define ONNX-Compatible Policy Wrapper\n",
    "\n",
    "This cell defines the `OnnxablePolicyPyTorch2` class, which wraps a PyTorch policy to make it compatible with ONNX export. The `forward` method ensures that observations are processed correctly and that the policy can be exported in a deterministic or stochastic manner as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnnxablePolicyPyTorch2(th.nn.Module):\n",
    "    def __init__(self, policy):\n",
    "        super().__init__()\n",
    "        self.policy = policy\n",
    "\n",
    "    def forward(self, observation):\n",
    "        # NOTE: Preprocessing is included, the only thing you need to do\n",
    "        # is transpose the images if needed so that they are channel first\n",
    "        # use deterministic=False if you want to export the stochastic policy\n",
    "        return self.policy(observation, deterministic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Load Pretrained PPO Model\n",
    "\n",
    "This cell loads a pretrained PPO model from the specified path and assigns it to the variable `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_model_path = \"ppo_5k.zip\"  # Change this path as needed\n",
    "device = \"cpu\"  # Change to \"cuda\" if GPU is available and desired\n",
    "\n",
    "model = PPO.load(ppo_model_path, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Export PyTorch Policy to ONNX\n",
    "\n",
    "This cell wraps the PPO model's policy with the `OnnxablePolicyPyTorch2` class and exports it to the ONNX format using a dummy input. The exported ONNX model can be used for inference in environments that support ONNX.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_pytorch2 = OnnxablePolicyPyTorch2(model.policy)\n",
    "observation_size = model.observation_space.shape\n",
    "dummy_input = th.randn(1, *observation_size)\n",
    "model_output_path = \"robofeeder_planning.onnx\"\n",
    "\n",
    "th.onnx.export(\n",
    "    onnx_pytorch2,\n",
    "    dummy_input,\n",
    "    model_output_path,\n",
    "    opset_version=17,  # neeed a \"updated\" version of onnx\n",
    "    input_names=[\"input\"],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Load and Validate the ONNX Model\n",
    "\n",
    "This cell loads the exported ONNX model, checks its validity, and creates an inference session using ONNX Runtime with the specified providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "onnx_model = onnx.load(model_output_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "ort_sess = rt.InferenceSession(model_output_path,providers=providers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edgegym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
