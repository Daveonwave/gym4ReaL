{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNCOMMENT TO INSTALL SKRL LIBRARY\n",
    "\n",
    "!pip install skrl[\"torch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b284b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/src/gym4real')  # <-- path to the *parent* of gym4real\n",
    "\n",
    "from gym4real.envs.robofeeder.rf_picking_v0 import robotEnv\n",
    "import torch\n",
    "from torch import nn\n",
    "# import the skrl components to build the RL system\n",
    "from skrl.agents.torch.ppo import PPO, PPO_DEFAULT_CONFIG\n",
    "from skrl.envs.loaders.torch import load_isaacgym_env_preview4\n",
    "from skrl.envs.wrappers.torch import wrap_env\n",
    "from skrl.memories.torch import RandomMemory\n",
    "from skrl.models.torch import DeterministicMixin, GaussianMixin, Model\n",
    "from skrl.resources.preprocessors.torch import RunningStandardScaler\n",
    "from skrl.resources.schedulers.torch import KLAdaptiveRL\n",
    "from skrl.trainers.torch import SequentialTrainer\n",
    "from skrl.utils import set_seed\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2bda4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[skrl:INFO] Seed: 50208689\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# seed for reproducibility\n",
    "set_seed()  # e.g. `set_seed(42)` for fixed seed\n",
    "\n",
    "\n",
    "# define shared model (stochastic and deterministic models) using mixins\n",
    "class Shared(GaussianMixin, DeterministicMixin, Model):\n",
    "    def __init__(self, observation_space, action_space, device, clip_actions=False,\n",
    "                 clip_log_std=True, min_log_std=-20, max_log_std=2, reduction=\"sum\"):\n",
    "        Model.__init__(self, observation_space, action_space, device)\n",
    "        GaussianMixin.__init__(self, clip_actions, clip_log_std, min_log_std, max_log_std, reduction)\n",
    "        DeterministicMixin.__init__(self, clip_actions)\n",
    "\n",
    "        self.net = nn.Sequential(nn.Linear(self.num_observations, 400),\n",
    "                                 nn.ELU(),\n",
    "                                 nn.Linear(400, 200),\n",
    "                                 nn.ELU(),\n",
    "                                 nn.Linear(200, 100),\n",
    "                                 nn.ELU())\n",
    "\n",
    "        self.mean_layer = nn.Linear(100, self.num_actions)\n",
    "        self.log_std_parameter = nn.Parameter(torch.zeros(self.num_actions))\n",
    "\n",
    "        self.value_layer = nn.Linear(100, 1)\n",
    "\n",
    "    def act(self, inputs, role):\n",
    "        if role == \"policy\":\n",
    "            return GaussianMixin.act(self, inputs, role)\n",
    "        elif role == \"value\":\n",
    "            return DeterministicMixin.act(self, inputs, role)\n",
    "\n",
    "    def compute(self, inputs, role):\n",
    "        if role == \"policy\":\n",
    "            self._shared_output = self.net(inputs[\"states\"])\n",
    "            return self.mean_layer(self._shared_output), self.log_std_parameter, {}\n",
    "        elif role == \"value\":\n",
    "            shared_output = self.net(inputs[\"states\"]) if self._shared_output is None else self._shared_output\n",
    "            self._shared_output = None\n",
    "            return self.value_layer(shared_output), {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a482dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/gymnasium/envs/registration.py:519: DeprecationWarning: \u001b[33mWARN: The environment gym4real/robofeeder-picking-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/usr/local/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:118: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "\u001b[38;20m[skrl:INFO] Environment wrapper: 'auto' (class: gymnasium.vector.vector_env.VectorEnv)\u001b[0m\n",
      "\u001b[38;20m[skrl:INFO] Environment wrapper: gymnasium\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# load and wrap the Isaac Gym environment\n",
    "config_path = \"/usr/src/gym4real/gym4real/envs/robofeeder/configuration.yaml\"\n",
    "\n",
    "env = wrap_env(gym.make_vec(\"gym4real/robofeeder-picking-v0\", num_envs=2, config_file= config_path))\n",
    "device = env.device\n",
    "\n",
    "# instantiate a memory as rollout buffer (any memory can be used for this)\n",
    "memory = RandomMemory(memory_size=32, num_envs=env.num_envs, device=device)\n",
    "\n",
    "\n",
    "# instantiate the agent's models (function approximators).\n",
    "# PPO requires 2 models, visit its documentation for more details\n",
    "# https://skrl.readthedocs.io/en/latest/api/agents/ppo.html#models\n",
    "models = {}\n",
    "models[\"policy\"] = Shared(env.observation_space, env.action_space, device)\n",
    "models[\"value\"] = models[\"policy\"]  # same instance: shared model\n",
    "\n",
    "\n",
    "# configure and instantiate the agent (visit its documentation to see all the options)\n",
    "# https://skrl.readthedocs.io/en/latest/api/agents/ppo.html#configuration-and-hyperparameters\n",
    "cfg = PPO_DEFAULT_CONFIG.copy()\n",
    "cfg[\"rollouts\"] = 32  # memory_size\n",
    "cfg[\"learning_epochs\"] = 5\n",
    "cfg[\"mini_batches\"] = 4  # 32 * 4096 / 32768\n",
    "cfg[\"discount_factor\"] = 0.99\n",
    "cfg[\"lambda\"] = 0.95\n",
    "cfg[\"learning_rate\"] = 5e-4\n",
    "cfg[\"learning_rate_scheduler\"] = KLAdaptiveRL\n",
    "cfg[\"learning_rate_scheduler_kwargs\"] = {\"kl_threshold\": 0.008}\n",
    "cfg[\"random_timesteps\"] = 0\n",
    "cfg[\"learning_starts\"] = 0\n",
    "cfg[\"grad_norm_clip\"] = 1.0\n",
    "cfg[\"ratio_clip\"] = 0.2\n",
    "cfg[\"value_clip\"] = 0.2\n",
    "cfg[\"clip_predicted_values\"] = True\n",
    "cfg[\"entropy_loss_scale\"] = 0.0\n",
    "cfg[\"value_loss_scale\"] = 2.0\n",
    "cfg[\"kl_threshold\"] = 0\n",
    "cfg[\"rewards_shaper\"] = lambda rewards, timestep, timesteps: rewards * 0.01\n",
    "cfg[\"state_preprocessor\"] = RunningStandardScaler\n",
    "cfg[\"state_preprocessor_kwargs\"] = {\"size\": env.observation_space, \"device\": device}\n",
    "cfg[\"value_preprocessor\"] = RunningStandardScaler\n",
    "cfg[\"value_preprocessor_kwargs\"] = {\"size\": 1, \"device\": device}\n",
    "# logging to TensorBoard and write checkpoints (in timesteps)\n",
    "cfg[\"experiment\"][\"write_interval\"] = 160\n",
    "cfg[\"experiment\"][\"checkpoint_interval\"] = 1600\n",
    "cfg[\"experiment\"][\"directory\"] = \"runs/torch/Humanoid\"\n",
    "\n",
    "agent = PPO(models=models,\n",
    "            memory=memory,\n",
    "            cfg=cfg,\n",
    "            observation_space=env.observation_space,\n",
    "            action_space=env.action_space,\n",
    "            device=device)\n",
    "\n",
    "\n",
    "# configure and instantiate the RL trainer\n",
    "cfg_trainer = {\"timesteps\": 10, \"headless\": True}\n",
    "trainer = SequentialTrainer(cfg=cfg_trainer, env=env, agents=agent)\n",
    "\n",
    "# start training\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
