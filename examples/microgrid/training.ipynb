{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2551241",
   "metadata": {},
   "source": [
    "# Training RL agents with ErNESTO-gym\n",
    "\n",
    "The notebooks provides a simple template to train and save the models of renowned RL agents.<br>\n",
    "Refer to the `testing.ipynb` notebook to test these models and compare them with deterministic strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ffdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "from ernestogym.envs import MicroGridEnv\n",
    "from ernestogym.envs.single_agent.utils import parameter_generator\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plot_colors = sns.color_palette()\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae561628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards(timestamps: list, res: dict, reward_type='weighted_reward', sampling_rate=10):\n",
    "    fig, ((ax1), (ax2), (ax3)) = plt.subplots(3, 1, figsize=(12, 9), tight_layout=True)\n",
    "    \n",
    "    trad_list = res[reward_type]['r_trad']   \n",
    "    op_list = res[reward_type]['r_op']     \n",
    "    clip_list = res[reward_type]['r_clip']     \n",
    "    \n",
    "    ax1.plot(timestamps[::sampling_rate], trad_list[::sampling_rate])\n",
    "    ax1.set(xlabel='Samples', ylabel='R_trad')         \n",
    "\n",
    "    ax2.plot(timestamps[::sampling_rate], op_list[::sampling_rate])\n",
    "    ax2.set(xlabel='Samples', ylabel='R_op') \n",
    "\n",
    "    ax3.plot(timestamps[::sampling_rate], clip_list[::sampling_rate])\n",
    "    ax3.set(xlabel='Samples', ylabel='R_clip')        \n",
    "\n",
    "def plot_cum_rewards(timestamps: list, res: dict, reward_type='weighted_reward', sampling_rate=10):\n",
    "    fig, ((ax1), (ax2), (ax3)) = plt.subplots(3, 1, figsize=(12, 9), tight_layout=True)\n",
    "    \n",
    "    trad_list = np.cumsum(res[reward_type]['r_trad'])\n",
    "    op_list = np.cumsum(res[reward_type]['r_op'])\n",
    "    clip_list = np.cumsum(res[reward_type]['r_clip'])     \n",
    "    \n",
    "    ax1.plot(timestamps[::sampling_rate], trad_list[::sampling_rate])\n",
    "    ax1.set(xlabel='Samples', ylabel='R_trad')         \n",
    "\n",
    "    ax2.plot(timestamps[::sampling_rate], op_list[::sampling_rate])\n",
    "    ax2.set(xlabel='Samples', ylabel='R_op') \n",
    "\n",
    "    ax3.plot(timestamps[::sampling_rate], clip_list[::sampling_rate])\n",
    "    ax3.set(xlabel='Samples', ylabel='R_clip')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9efdeb",
   "metadata": {},
   "source": [
    "## Environment Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da659048",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_options = \"ernestogym/ernesto/data/battery/pack.yaml\"\n",
    "# ecm = \"ernestogym/ernesto/data/battery/models/electrical/thevenin_pack.yaml\"\n",
    "ecm = \"ernestogym/ernesto/data/battery/models/electrical/thevenin_fading_pack.yaml\"\n",
    "r2c = \"ernestogym/ernesto/data/battery/models/thermal/r2c_thermal_pack.yaml\"\n",
    "bolun = \"ernestogym/ernesto/data/battery/models/aging/bolun_pack.yaml\"\n",
    "# world = \"ernestogym/envs/single_agent/world_deg.yaml\"\n",
    "world = \"ernestogym/envs/single_agent/world_fading.yaml\"\n",
    "\n",
    "params = parameter_generator(\n",
    "    battery_options=pack_options,\n",
    "    electrical_model=ecm,\n",
    "    thermal_model=r2c,\n",
    "    aging_model=bolun,\n",
    "    world_options=world,\n",
    "    use_reward_normalization=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292e747",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = MicroGridEnv(settings=params)\n",
    "\n",
    "print('Size of State Space: ', env.observation_space.shape)\n",
    "print('Observation Space: ', env.spaces.keys())\n",
    "print('Size of Action Space: ', env.action_space.shape)\n",
    "print('Min action: ', env.action_space.low)\n",
    "print('Max action: ', env.action_space.high)\n",
    "print('Sample State: ', env.observation_space.sample())\n",
    "print('Sample Action: ', env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84953099",
   "metadata": {},
   "source": [
    "## Experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b1615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_steps = len(env.demand)\n",
    "num_steps = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab00ac",
   "metadata": {},
   "source": [
    "## PPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a checkpoint every 1000 steps\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=num_steps,\n",
    "    save_path=\"./examples/single_agent/models/\",\n",
    "    name_prefix=\"ppo\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170df98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(MlpPolicy, env, verbose=False, gamma=0.9)\n",
    "\n",
    "model.learn(total_timesteps=num_steps,\n",
    "            progress_bar=True, \n",
    "            reset_num_timesteps=False,\n",
    "            callback=[checkpoint_callback],\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7689d79",
   "metadata": {},
   "source": [
    "## A2C Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b334bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a checkpoint every 1000 steps\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=num_steps,\n",
    "    save_path=\"./examples/single_agent/models/\",\n",
    "    name_prefix=\"a2c\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1010a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C(MlpPolicy, env, verbose=False, gamma=0.9)\n",
    "\n",
    "model.learn(total_timesteps=num_steps,\n",
    "            progress_bar=True, \n",
    "            reset_num_timesteps=False,\n",
    "            callback=[checkpoint_callback],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdeacdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ernesto-gym",
   "language": "python",
   "name": "ernesto-gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
